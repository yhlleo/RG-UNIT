dataset: CelebA               # dataset name              
image_save_iter: 10000        # How often do you want to save output images during training
image_display_iter: 500       # How often do you want to display output images during training
display_size: 8               # How many images do you want to display each time
snapshot_save_iter: 10000     # How often do you want to save trained models
log_iter: 100                 # How often do you want to log the training stats

# optimization options
max_iter: 750000              # maximum number of training iterations
batch_size: 1                 # batch size
weight_decay: 0.0001          # weight decay
beta1: 0.5                    # Adam parameter
beta2: 0.999                  # Adam parameter
init: kaiming                 # initialization [gaussian/kaiming/xavier/orthogonal]
lr: 0.0001                    # initial learning rate
lr_policy: cosa               # learning rate scheduler, [const/step/cosa]
step_size: 100000             # how often to decay learning rate
eta_min: 0.0                  # for cosa scheduler
t_mult: 1                     # for cosa scheduler
gamma: 0.5                    # how much to decay learning rate
stddev: 0.5                   # standard deviation
gan_w: 1                      # weight of adversarial loss
cls_w: 1                      # weight of classification loss
kl_w: 0.1                     # weight of Kullback–Leibler divergence
recon_x_w: 10                 # weight of image reconstruction loss
recon_s_w: 1                  # weight of style reconstruction loss
recon_c_w: 0.5                # weight of content reconstruction loss
recon_x_cyc_w: 10             # weight of explicit style augmented cycle consistency loss
vgg_w: 0.1                    # weight of domain-invariant perceptual loss
gp_w: 0                       # weight of gradient panelty loss
dist_w: 0.1                   # weight of distance constraints 
dist_mode: none               # em, Earth Mover; kl/kls, Kullback–Leibler Divergence
dist_type: none

c_dim: 8                      # selected attributes of face
v_dim: 1                      # length of style code of each domain

# retrieval model options (conv model is hardcoded in retrieval_networks.py)
ret:
  retrieval_checkpoint: ./models/ret_gmm_00020000.pt
  img_emb_path: ./datasets/images_embeddings_gmm.json
  num_results: 3
  num_layers: 3
  hidden_size: 512
  embed_dim: 100
  norm: ln                    # normalization layer [none/bn/in/ln]
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  pad_type: reflect           # padding type [zero/reflect]
  distance_norm_degree: 2
  c_dim: 8                    # latent dimension for each attrobute
  num_cls: 5                 

# model options
gen:
  dim: 64                     # number of filters in the bottommost layer
  mlp_dim: 256                # number of filters in MLP
  c_dim: 8                    # selected attributes of face
  num_cls: 5                 
  activ: relu                 # activation function [relu/lrelu/prelu/selu/tanh]
  style_downsample: 5         # number of downsampling layers in style encoder
  content_downsample: 2       # number of downsampling layers in content encoder
  n_res: 4                    # number of residual blocks in content encoder/decoder
  pad_type: reflect           # padding type [zero/reflect]
  use_attention: True         # using attention [True/False]
  use_map: True               # use fc layers to the CNN extracted style features [True/False]
  use_dsn: True               # use Deeply-supervised Nets [True/False]
  num_results: 3              # number of retrieved images

dis:
  dim: 64                     # number of filters in the bottommost layer
  norm: none                  # normalization layer [none/bn/in/ln]
  activ: lrelu                # activation function [relu/lrelu/prelu/selu/tanh]
  n_layer: 5                  # number of layers in D
  gan_type: lsgan             # GAN loss [lsgan/nsgan/wgan]
  num_scales: 2               # number of scales
  pad_type: reflect           # padding type [zero/reflect]
  num_cls: 5
  image_size: 128
  dataset: CelebA


# data options
input_dim: 3                  # number of image channels [1/3]
num_workers: 2                # number of data loading threads
image_size: 128               # first resize the shortest image side to this size
crop_size: 178                # random crop image of this height
data_root: ../datasets/celeba/images
train_list: ./datasets/celeba/list_attr_celeba-0.75.txt
test_list: ./datasets/celeba/list_attr_celeba-val.txt
pretrained_embed: './datasets/embeddings.npy'
use_pretrain: True
gen_pretrain: ./models/gmmunit_gen-0.75.pt
dis_pretrain: ./models/gmmunit_dis-0.75.pt
