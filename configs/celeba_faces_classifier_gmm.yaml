dataset: CelebA               # dataset name              
snapshot_save_iter: 5000      # How often do you want to save trained models (Also saving them with when val loss is best)
log_iter: 200                 # How often do you want to log the training stats
valid_step: 1000              # 500
checkpoint: ./models/best_model.pt

# optimization options
num_classes: 8
max_iter: 100000              # maximum number of training iterations
batch_size: 64                # batch size
weight_decay: 0.0001          # weight decay
momentum: 0.9
lr: 0.01                      # initial learning rate # 0.1
lr_policy: step               # learning rate scheduler
step_size: 20000               # how often to decay learning rate
gamma: 0.5                    # how much to decay learning rate
use_pretrained: True

# data options
input_dim: 3                  # number of image channels [1/3]
num_workers: 2                # number of data loading threads
image_size: 224               # first resize the shortest image side to this size
crop_size: 178                # random crop image of this height
data_root: ./datasets/celeba/images
train_list: ./datasets/celeba/list_attr_celeba-all.txt
test_list: ./datasets/celeba/list_attr_celeba-val.txt
attr_path: ./datasets/celeba/list_attr_celeba.txt

# eval options
eval_generated: True                                                        # evaluate with generated images instead of test images
gen_results: ./results/celeba_faces_gmmunit_retrieval-src2trg_celeba-label-1e4      # generated images path
gen_gt:  ./valid/trg_celeba-1e4.lst                                      # target attributes of the generated images

